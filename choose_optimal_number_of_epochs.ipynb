{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Choose optimal number of epochs to train a neural network in Keras</h3>\n",
    "<p>One of the critical issues while training a neural network on the sample data is Overfitting. When the number of epochs used to train a neural network model is more than necessary, the training model learns patterns that are specific to sample data to a great extent. This makes the model incapable to perform well on a new dataset. This model gives high accuracy on the training set (sample data) but fails to achieve good accuracy on the test set. In other words, the model loses generalization capacity by overfitting the training data. To mitigate overfitting and to increase the generalization capacity of the neural network, the model should be trained for an optimal number of epochs. A part of the training data is dedicated to the validation of the model, to check the performance of the model after each epoch of training. Loss and accuracy on the training set as well as on the validation set are monitored to look over the epoch number after which the model starts overfitting.</p>\n",
    "<h3>keras.callbacks.callbacks.EarlyStopping()</h3>\n",
    "<p>Either loss/accuracy values can be monitored by the Early stopping call back function. If the loss is being monitored, training comes to halt when there is an increment observed in loss values. Or, If accuracy is being monitored, training comes to halt when there is a decrement observed in accuracy values.</p>\n",
    "<p>monitor: The value to be monitored by the function should be assigned. It can be validation loss or validation accuracy.\n",
    "mode: It is the mode in which change in the quantity monitored should be observed. This can be ‘min’ or ‘max’ or ‘auto’. When the monitored value is loss, its value is ‘min’. When the monitored value is accuracy, its value is ‘max’. When the mode is set is ‘auto’, the function automatically monitors with the suitable mode.\n",
    "min_delta: The minimum value should be set for the change to be considered i.e., Change in the value being monitored should be higher than ‘min_delta’ value.\n",
    "patience: Patience is the number of epochs for the training to be continued after the first halt. The model waits for patience number of epochs for any improvement in the model.\n",
    "verbose: Verbose is an integer value-0, 1 or 2. This value is to select the way in which the progress is displayed while training.\n",
    "Verbose = 0: Silent mode-Nothing is displayed in this mode.\n",
    "Verbose = 1: A bar depicting the progress of training is displayed.\n",
    "Verbose = 2: In this mode, one line per epoch, showing the progress of training per epoch is displayed.\n",
    "restore_best_weights: This is a boolean value. True value restores the weights which are optimal.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers,callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##loading data\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()\n",
    "#Reshaping Data\n",
    "train_images = train_images.reshape((train_images.shape[0],\n",
    "                                     train_images.shape[1],\n",
    "                                     train_images.shape[2], 1))\n",
    "test_images = test_images.reshape((test_images.shape[0],\n",
    "                                   test_images.shape[1],\n",
    "                                   test_images.shape[2], 1))\n",
    "# Scaling down pixel values\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255\n",
    " # Encoding labels to a binary class matrix\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121930 (476.29 KB)\n",
      "Trainable params: 121930 (476.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating the Model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',  input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = train_images[:10000]\n",
    "partial_images = train_images[10000:]\n",
    "val_labels = y_train[:10000]\n",
    "partial_labels = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',  # You can choose another optimizer\n",
    "              loss='categorical_crossentropy',  # Choose an appropriate loss function\n",
    "              metrics=['accuracy'])  # Add any metrics you want to track during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.2453 - accuracy: 0.9294 - val_loss: 0.0821 - val_accuracy: 0.9761\n",
      "Epoch 2/25\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0643 - accuracy: 0.9804 - val_loss: 0.0602 - val_accuracy: 0.9825\n",
      "Epoch 3/25\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0444 - accuracy: 0.9864 - val_loss: 0.0535 - val_accuracy: 0.9850\n",
      "Epoch 4/25\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.0452 - val_accuracy: 0.9871\n",
      "Epoch 5/25\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
      "Epoch 6/25\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
      "Epoch 7/25\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0430 - val_accuracy: 0.9880\n",
      "Epoch 8/25\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.0372 - val_accuracy: 0.9885\n",
      "Epoch 9/25\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0474 - val_accuracy: 0.9886\n",
      "Epoch 10/25\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0420 - val_accuracy: 0.9895\n",
      "Epoch 11/25\n",
      "391/391 [==============================] - 14s 37ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0465 - val_accuracy: 0.9878\n",
      "Epoch 12/25\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
      "Epoch 13/25\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0558 - val_accuracy: 0.9869\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_images, partial_labels, batch_size=128,\n",
    "                    epochs=25, validation_data=(val_images, val_labels),\n",
    "                    callbacks=[earlystopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0376 - val_accuracy: 0.9892\n",
      "Epoch 2/45\n",
      "391/391 [==============================] - 15s 37ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0462 - val_accuracy: 0.9881\n",
      "Epoch 3/45\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0486 - val_accuracy: 0.9888\n",
      "Epoch 4/45\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0440 - val_accuracy: 0.9882\n",
      "Epoch 5/45\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0451 - val_accuracy: 0.9900\n",
      "Epoch 6/45\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0458 - val_accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_images, partial_labels, batch_size=128,\n",
    "                    epochs=45, validation_data=(val_images, val_labels),\n",
    "                    callbacks=[earlystopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
